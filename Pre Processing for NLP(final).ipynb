{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a115c6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\u\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\u\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\u\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\u\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\u\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\u\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#Install and Import NLTK library (Natural Language Toolkit)\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef20738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\u\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\u\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\u\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data files\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f22d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take an example text to perform pre processing steps\n",
    "text=\"\"\"Natural language processing is an exciting field of artificial intelligence \n",
    "that focuses on the interaction between computers and humans through language. \n",
    "It involves various techniques to analyze and understand human language.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e497c90",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad54955",
   "metadata": {},
   "source": [
    "Tokenization is the process of breaking down text into smaller units called tokens. These tokens can be words, subwords, or characters, depending on the level of granularity needed for a particular task. Tokenization is a crucial step in natural language processing (NLP) and text analysis because it converts raw text into a structured format that algorithms can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a42c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6730743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentence Tokenized\n",
    "sent_tokenized=sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "289ef553",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************\n",
      "Natural language processing is an exciting field of artificial intelligence \n",
      "that focuses on the interaction between computers and humans through language.\n",
      "***********************************\n",
      "It involves various techniques to analyze and understand human language.\n"
     ]
    }
   ],
   "source": [
    "for sentence in sent_tokenized:\n",
    "    print(\"***********************************\")\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8fc94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word tokenize\n",
    "text_tokenized=word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cee1b74e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', 'is', 'an', 'exciting', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'language', '.', 'It', 'involves', 'various', 'techniques', 'to', 'analyze', 'and', 'understand', 'human', 'language', '.']\n"
     ]
    }
   ],
   "source": [
    "print(text_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96110f12",
   "metadata": {},
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad11d5a",
   "metadata": {},
   "source": [
    "The words which are generally filtered out out before processing a natural language are called stop words . These are the words which do not carry meaningful information about the content of the text. Stop words are used to remove noise from the data and speed up the computation process. Ex:the\", \"is\", \"at\", \"which\", \"and\", \"on\", \"in\", \"of\", \"to\", etc., we can even include punctuations here\n",
    "\n",
    "To perform the stop words operation, we will use the NLTK library. NLTK stands for Natural Language Toolkit. It is a leading platform for building Python programs to work with human language data, particularly in the field of natural language processing (NLP). NLTK provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, among other NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c861a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop words removal\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b3e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebce1e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7352a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_without_stopwords=[word for word in text_tokenized if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b3e7720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of text before removing stop words 33\n",
      "The length of text after removing stop words 22\n"
     ]
    }
   ],
   "source": [
    "print(\"The length of text before removing stop words\",len(text_tokenized))\n",
    "print(\"The length of text after removing stop words\",len(text_without_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12905430",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d2535",
   "metadata": {},
   "source": [
    "\n",
    "In natural language processing (NLP), stemming is the process of reducing words to their root or base form, also known as the stem. The main goal of stemming is to reduce inflected words to their common base form, which can help improve text analysis and information retrieval tasks by treating different forms of a word as the same entity.\n",
    "\n",
    "For example, stemming would convert words like \"running\", \"runs\", and \"ran\" to the common base form \"run\". Similarly, words like \"play\", \"playing\", and \"played\" would all be stemmed to \"play\".\n",
    "\n",
    "Stemming algorithms typically work by removing suffixes from words to obtain the root form. These algorithms are rule-based and operate by applying a series of rules to trim off common suffixes. However, stemming algorithms do not always produce accurate or linguistically valid results, as they may sometimes produce stems that are not actual words or may result in stems that are not semantically related.\n",
    "\n",
    "Despite its limitations, stemming is still widely used in NLP tasks such as text normalization, information retrieval, and document clustering. It can help reduce the dimensionality of text data and improve the performance of certain text processing tasks. Popular stemming algorithms include the Porter Stemmer and the Snowball Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f338652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32df6fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "455a79fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chang\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem(\"changing\"))\n",
    "#It removes its suffixes and changes it to chang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4563b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"change\",\"changed\",\"changing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "839057be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change <---> chang\n",
      "changed <---> chang\n",
      "changing <---> chang\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,\"<--->\",stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534e088",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d76d43",
   "metadata": {},
   "source": [
    "Lemmatization, like stemming, is a natural language processing (NLP) technique used to reduce words to their base or dictionary form, known as the lemma. However, unlike stemming, lemmatization considers the context and meaning of a word when determining its lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9112c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8979276",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78ecf024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"changing\",pos=\"v\"))\n",
    "#pos(Parts of speech which we have chosen as verb(\"v\") so it changes it into verb base form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9aa9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[\"change\",\"changed\",\"changing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44483526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change <---> change\n",
      "changed <---> change\n",
      "changing <---> change\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,\"<--->\",lemmatizer.lemmatize(word,pos=\"v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959cfc1d",
   "metadata": {},
   "source": [
    "## Name Entity Recognition(NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85882828",
   "metadata": {},
   "source": [
    "Named Entity Recognition (NER) is a natural language processing (NLP) technique that aims to identify and classify named entities within a text into predefined categories such as the names of persons, organizations, locations, expressions of times, quantities, monetary values, percentages, etc. The primary goal of NER is to extract and label these entities to provide structure and meaning to unstructured text data.\n",
    "\n",
    "For instance, in the sentence \"John works at Google in California\", NER would identify \"John\" as a PERSON entity, \"Google\" as an ORGANIZATION entity, and \"California\" as a LOCATION entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a2a68b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\u\\anaconda3\\lib\\site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\u\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\u\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\u\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\u\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\u\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\u\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\u\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\u\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
      "Collecting en-core-web-md==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
      "     ---------------------------------------- 0.0/42.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/42.8 MB 393.8 kB/s eta 0:01:49\n",
      "     --------------------------------------- 0.1/42.8 MB 819.2 kB/s eta 0:00:53\n",
      "     ---------------------------------------- 0.2/42.8 MB 1.1 MB/s eta 0:00:38\n",
      "     ---------------------------------------- 0.3/42.8 MB 1.1 MB/s eta 0:00:38\n",
      "     ---------------------------------------- 0.5/42.8 MB 1.7 MB/s eta 0:00:25\n",
      "      --------------------------------------- 0.7/42.8 MB 2.1 MB/s eta 0:00:20\n",
      "      --------------------------------------- 0.9/42.8 MB 2.4 MB/s eta 0:00:18\n",
      "      --------------------------------------- 1.0/42.8 MB 2.5 MB/s eta 0:00:17\n",
      "     - -------------------------------------- 1.3/42.8 MB 2.7 MB/s eta 0:00:16\n",
      "     - -------------------------------------- 1.4/42.8 MB 2.7 MB/s eta 0:00:16\n",
      "     - -------------------------------------- 1.6/42.8 MB 2.8 MB/s eta 0:00:15\n",
      "     - -------------------------------------- 1.6/42.8 MB 2.8 MB/s eta 0:00:15\n",
      "     - -------------------------------------- 2.1/42.8 MB 3.2 MB/s eta 0:00:13\n",
      "     -- ------------------------------------- 2.3/42.8 MB 3.2 MB/s eta 0:00:13\n",
      "     -- ------------------------------------- 2.4/42.8 MB 3.2 MB/s eta 0:00:13\n",
      "     -- ------------------------------------- 2.7/42.8 MB 3.3 MB/s eta 0:00:13\n",
      "     -- ------------------------------------- 2.9/42.8 MB 3.4 MB/s eta 0:00:12\n",
      "     -- ------------------------------------- 3.1/42.8 MB 3.5 MB/s eta 0:00:12\n",
      "     --- ------------------------------------ 3.5/42.8 MB 3.6 MB/s eta 0:00:11\n",
      "     --- ------------------------------------ 3.7/42.8 MB 3.7 MB/s eta 0:00:11\n",
      "     --- ------------------------------------ 4.0/42.8 MB 3.9 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 4.3/42.8 MB 4.0 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 4.6/42.8 MB 4.0 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 4.9/42.8 MB 4.2 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 5.1/42.8 MB 4.2 MB/s eta 0:00:10\n",
      "     ---- ----------------------------------- 5.3/42.8 MB 4.2 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 5.6/42.8 MB 4.2 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 5.7/42.8 MB 4.2 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 5.8/42.8 MB 4.1 MB/s eta 0:00:10\n",
      "     ----- ---------------------------------- 5.9/42.8 MB 4.0 MB/s eta 0:00:10\n",
      "     ----- ---------------------------------- 6.2/42.8 MB 4.1 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 6.3/42.8 MB 4.1 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 6.4/42.8 MB 4.0 MB/s eta 0:00:10\n",
      "     ------ --------------------------------- 6.5/42.8 MB 4.0 MB/s eta 0:00:10\n",
      "     ------ --------------------------------- 6.8/42.8 MB 4.0 MB/s eta 0:00:10\n",
      "     ------ --------------------------------- 7.0/42.8 MB 4.0 MB/s eta 0:00:09\n",
      "     ------ --------------------------------- 7.2/42.8 MB 4.0 MB/s eta 0:00:09\n",
      "     ------ --------------------------------- 7.2/42.8 MB 3.9 MB/s eta 0:00:10\n",
      "     ------ --------------------------------- 7.5/42.8 MB 3.9 MB/s eta 0:00:09\n",
      "     ------- -------------------------------- 7.6/42.8 MB 3.9 MB/s eta 0:00:09\n",
      "     ------- -------------------------------- 7.9/42.8 MB 4.0 MB/s eta 0:00:09\n",
      "     ------- -------------------------------- 7.9/42.8 MB 4.0 MB/s eta 0:00:09\n",
      "     ------- -------------------------------- 8.3/42.8 MB 4.0 MB/s eta 0:00:09\n",
      "     ------- -------------------------------- 8.4/42.8 MB 4.0 MB/s eta 0:00:09\n",
      "     ------- -------------------------------- 8.4/42.8 MB 3.9 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 8.7/42.8 MB 3.9 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 8.8/42.8 MB 3.9 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 9.1/42.8 MB 3.9 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 9.3/42.8 MB 3.9 MB/s eta 0:00:09\n",
      "     -------- ------------------------------- 9.5/42.8 MB 3.9 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 9.7/42.8 MB 3.9 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 9.9/42.8 MB 3.9 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 10.1/42.8 MB 3.9 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 10.2/42.8 MB 3.9 MB/s eta 0:00:09\n",
      "     --------- ------------------------------ 10.4/42.8 MB 4.1 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 10.6/42.8 MB 4.2 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 10.9/42.8 MB 4.2 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 11.2/42.8 MB 4.3 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 11.4/42.8 MB 4.3 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 11.4/42.8 MB 4.3 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 11.6/42.8 MB 4.2 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 11.7/42.8 MB 4.2 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 11.9/42.8 MB 4.3 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 12.1/42.8 MB 4.2 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 12.3/42.8 MB 4.1 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 12.5/42.8 MB 4.2 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 12.7/42.8 MB 4.1 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 12.9/42.8 MB 4.2 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 13.1/42.8 MB 4.1 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 13.3/42.8 MB 4.1 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 13.5/42.8 MB 4.1 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 13.7/42.8 MB 4.1 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 13.9/42.8 MB 4.0 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 14.0/42.8 MB 4.0 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 14.1/42.8 MB 3.9 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 14.4/42.8 MB 3.9 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 14.5/42.8 MB 3.9 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 14.8/42.8 MB 3.9 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 15.0/42.8 MB 3.9 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 15.4/42.8 MB 3.9 MB/s eta 0:00:07\n",
      "     -------------- ------------------------- 15.5/42.8 MB 3.9 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 15.6/42.8 MB 3.9 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 15.8/42.8 MB 3.9 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 16.1/42.8 MB 4.0 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 16.4/42.8 MB 4.0 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 16.6/42.8 MB 4.0 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 16.8/42.8 MB 4.1 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 16.9/42.8 MB 4.0 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 17.1/42.8 MB 4.0 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 17.1/42.8 MB 4.0 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 17.3/42.8 MB 4.0 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 17.5/42.8 MB 4.0 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 17.7/42.8 MB 4.0 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 17.8/42.8 MB 4.0 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 17.9/42.8 MB 3.9 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 18.2/42.8 MB 3.9 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 18.3/42.8 MB 3.9 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 18.4/42.8 MB 3.9 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 18.6/42.8 MB 3.9 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 18.6/42.8 MB 3.9 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 18.9/42.8 MB 3.9 MB/s eta 0:00:07\n",
      "     ----------------- ---------------------- 19.0/42.8 MB 3.9 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 19.3/42.8 MB 3.9 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 19.4/42.8 MB 3.9 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 19.5/42.8 MB 3.9 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 19.6/42.8 MB 3.8 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 19.7/42.8 MB 3.8 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 19.8/42.8 MB 3.7 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 19.9/42.8 MB 3.7 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 20.1/42.8 MB 3.7 MB/s eta 0:00:07\n",
      "     ------------------- -------------------- 20.3/42.8 MB 3.7 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 20.5/42.8 MB 3.7 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 20.7/42.8 MB 3.8 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 20.9/42.8 MB 3.7 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 21.1/42.8 MB 3.7 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 21.1/42.8 MB 3.7 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 21.2/42.8 MB 3.7 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 21.3/42.8 MB 3.6 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 21.4/42.8 MB 3.5 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 21.5/42.8 MB 3.5 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 21.7/42.8 MB 3.5 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 21.7/42.8 MB 3.5 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 21.8/42.8 MB 3.5 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 21.9/42.8 MB 3.5 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 22.0/42.8 MB 3.4 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 22.1/42.8 MB 3.4 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 22.4/42.8 MB 3.4 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 22.6/42.8 MB 3.4 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 22.8/42.8 MB 3.4 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 23.0/42.8 MB 3.4 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 23.2/42.8 MB 3.4 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 23.5/42.8 MB 3.4 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 23.6/42.8 MB 3.4 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 23.7/42.8 MB 3.4 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 23.8/42.8 MB 3.4 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 23.9/42.8 MB 3.3 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 24.0/42.8 MB 3.4 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 24.1/42.8 MB 3.3 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 24.2/42.8 MB 3.3 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 24.2/42.8 MB 3.3 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 24.4/42.8 MB 3.3 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 24.4/42.8 MB 3.2 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 24.6/42.8 MB 3.2 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 24.7/42.8 MB 3.2 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 24.9/42.8 MB 3.2 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 25.0/42.8 MB 3.2 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 25.1/42.8 MB 3.1 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 25.2/42.8 MB 3.1 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 25.4/42.8 MB 3.1 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 25.5/42.8 MB 3.1 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 25.6/42.8 MB 3.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 25.6/42.8 MB 3.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 25.6/42.8 MB 3.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 25.6/42.8 MB 3.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 25.6/42.8 MB 3.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 25.6/42.8 MB 3.0 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 25.9/42.8 MB 2.9 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 25.9/42.8 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 26.1/42.8 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 26.2/42.8 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 26.4/42.8 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 26.4/42.8 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 26.5/42.8 MB 2.8 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 26.6/42.8 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 26.7/42.8 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 26.7/42.8 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 26.8/42.8 MB 2.7 MB/s eta 0:00:07\n",
      "     ------------------------- -------------- 27.0/42.8 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 27.2/42.8 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 27.2/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 27.3/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 27.4/42.8 MB 2.7 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 27.4/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 27.6/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 27.7/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     ------------------------- -------------- 27.8/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------- ------------- 28.0/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------- ------------- 28.1/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------- ------------- 28.2/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------- ------------- 28.4/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------- ------------- 28.6/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     -------------------------- ------------- 28.8/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     --------------------------- ------------ 29.0/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     --------------------------- ------------ 29.2/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     --------------------------- ------------ 29.3/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     --------------------------- ------------ 29.5/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     --------------------------- ------------ 29.5/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     --------------------------- ------------ 29.5/42.8 MB 2.6 MB/s eta 0:00:06\n",
      "     --------------------------- ------------ 29.5/42.8 MB 2.5 MB/s eta 0:00:06\n",
      "     --------------------------- ------------ 29.6/42.8 MB 2.5 MB/s eta 0:00:06\n",
      "     --------------------------- ------------ 29.8/42.8 MB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 30.0/42.8 MB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 30.0/42.8 MB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 30.0/42.8 MB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 30.1/42.8 MB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 30.2/42.8 MB 2.5 MB/s eta 0:00:06\n",
      "     ---------------------------- ----------- 30.5/42.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 30.7/42.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 30.8/42.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ---------------------------- ----------- 31.0/42.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ----------------------------- ---------- 31.1/42.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ----------------------------- ---------- 31.2/42.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ----------------------------- ---------- 31.4/42.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ----------------------------- ---------- 31.6/42.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ----------------------------- ---------- 31.8/42.8 MB 2.5 MB/s eta 0:00:05\n",
      "     ----------------------------- ---------- 32.0/42.8 MB 2.6 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 32.1/42.8 MB 2.6 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 32.2/42.8 MB 2.6 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 32.3/42.8 MB 2.6 MB/s eta 0:00:05\n",
      "     ------------------------------ --------- 32.6/42.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 32.7/42.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 33.0/42.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 33.1/42.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 33.3/42.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 33.4/42.8 MB 2.6 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 33.4/42.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 33.5/42.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 33.7/42.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 33.8/42.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 34.0/42.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 34.1/42.8 MB 2.5 MB/s eta 0:00:04\n",
      "     ------------------------------- -------- 34.1/42.8 MB 2.5 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 34.3/42.8 MB 2.5 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 34.5/42.8 MB 2.6 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 34.7/42.8 MB 2.6 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 34.8/42.8 MB 2.6 MB/s eta 0:00:04\n",
      "     -------------------------------- ------- 35.0/42.8 MB 2.6 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 35.2/42.8 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 35.3/42.8 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 35.5/42.8 MB 2.7 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 35.7/42.8 MB 2.7 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 36.0/42.8 MB 2.9 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 36.0/42.8 MB 2.8 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 36.1/42.8 MB 2.8 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 36.3/42.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 36.4/42.8 MB 2.9 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 36.4/42.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 36.6/42.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 36.6/42.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 36.7/42.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 36.8/42.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 36.9/42.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------------------------- ----- 37.1/42.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 37.3/42.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 37.4/42.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 37.5/42.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 37.5/42.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 37.6/42.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 37.7/42.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 37.9/42.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 37.9/42.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 37.9/42.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 38.0/42.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 38.1/42.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 38.2/42.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 38.3/42.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 38.4/42.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 38.5/42.8 MB 2.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 38.6/42.8 MB 2.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 38.6/42.8 MB 2.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 38.6/42.8 MB 2.7 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 38.6/42.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 38.7/42.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 38.8/42.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 38.8/42.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 39.0/42.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 39.0/42.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 39.2/42.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 39.4/42.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 39.6/42.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 39.6/42.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 39.6/42.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 39.8/42.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 39.9/42.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 40.2/42.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 40.3/42.8 MB 2.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 40.4/42.8 MB 2.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 40.6/42.8 MB 2.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.7/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.8/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.0/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.1/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.2/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.3/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.5/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.5/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.7/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.8/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.0/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.3/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.4/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.5/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.6/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.7/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.8/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.8/42.8 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 42.8/42.8 MB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from en-core-web-md==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\u\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\u\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\u\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\u\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\u\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\u\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\u\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\u\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\u\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\u\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44ed7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46462964",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc7e7c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example text\n",
    "txt=\"\"\"\n",
    "John Smith works at XYZ Corporation located in New York City.\n",
    "He is currently leading a project on artificial intelligence. \n",
    "Last week, he attended a conference on machine learning in San Francisco.\n",
    "His colleague, Sarah Johnson, presented their team's research on natural language processing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85f5bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "270e0dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    John Smith\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " works at \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    XYZ Corporation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " located in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York City\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".<br>He is currently leading a project on artificial intelligence. <br>\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Last week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", he attended a conference on machine learning in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    San Francisco\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".<br>His colleague, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sarah Johnson\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", presented their team's research on natural language processing.<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(spacy.displacy.render(doc,style=\"ent\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b11d7024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(John Smith, XYZ Corporation, New York City, Last week, San Francisco, Sarah Johnson)\n"
     ]
    }
   ],
   "source": [
    "print (doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57b7db22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Smith <----> PERSON\n",
      "XYZ Corporation <----> ORG\n",
      "New York City <----> GPE\n",
      "Last week <----> DATE\n",
      "San Francisco <----> GPE\n",
      "Sarah Johnson <----> PERSON\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(entity,\"<---->\",entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "444cd5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Countries, cities, states'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To understand about these entities\n",
    "spacy.explain(\"GPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5046e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "John Smith works at XYZ Corporation located in New York City.\n",
       "He is currently leading a project on artificial intelligence. \n",
       "Last week, he attended a conference on machine learning in San Francisco.\n",
       "His colleague, Sarah Johnson, presented their team's research on natural language processing."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7d6b8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <---> SPACE\n",
      "John <---> PROPN\n",
      "Smith <---> PROPN\n",
      "works <---> VERB\n",
      "at <---> ADP\n",
      "XYZ <---> PROPN\n",
      "Corporation <---> PROPN\n",
      "located <---> VERB\n",
      "in <---> ADP\n",
      "New <---> PROPN\n",
      "York <---> PROPN\n",
      "City <---> PROPN\n",
      ". <---> PUNCT\n",
      "\n",
      " <---> SPACE\n",
      "He <---> PRON\n",
      "is <---> AUX\n",
      "currently <---> ADV\n",
      "leading <---> VERB\n",
      "a <---> DET\n",
      "project <---> NOUN\n",
      "on <---> ADP\n",
      "artificial <---> ADJ\n",
      "intelligence <---> NOUN\n",
      ". <---> PUNCT\n",
      "\n",
      " <---> SPACE\n",
      "Last <---> ADJ\n",
      "week <---> NOUN\n",
      ", <---> PUNCT\n",
      "he <---> PRON\n",
      "attended <---> VERB\n",
      "a <---> DET\n",
      "conference <---> NOUN\n",
      "on <---> ADP\n",
      "machine <---> NOUN\n",
      "learning <---> NOUN\n",
      "in <---> ADP\n",
      "San <---> PROPN\n",
      "Francisco <---> PROPN\n",
      ". <---> PUNCT\n",
      "\n",
      " <---> SPACE\n",
      "His <---> PRON\n",
      "colleague <---> NOUN\n",
      ", <---> PUNCT\n",
      "Sarah <---> PROPN\n",
      "Johnson <---> PROPN\n",
      ", <---> PUNCT\n",
      "presented <---> VERB\n",
      "their <---> PRON\n",
      "team <---> NOUN\n",
      "'s <---> PART\n",
      "research <---> NOUN\n",
      "on <---> ADP\n",
      "natural <---> ADJ\n",
      "language <---> NOUN\n",
      "processing <---> NOUN\n",
      ". <---> PUNCT\n",
      "\n",
      " <---> SPACE\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(word,\"<--->\",word.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a616d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all this pre processing techniques and make a function\n",
    "#Importing libraries\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=stopwords.words(\"english\")\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48d88d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    #Removing special characters\n",
    "    text=re.sub(r\"[^a-z0-9A-Z ]\",\"\",sentence).lower()\n",
    "    #Tokenize data\n",
    "    text_tokenized=word_tokenize(text)\n",
    "    #Remove stop words\n",
    "    text_without_stopwords=[word for word in text_tokenized if word not in stop_words]\n",
    "    #Joining the sentence\n",
    "    text_without_stopwords=\" \".join(text_without_stopwords)\n",
    "    #lemmatizing words\n",
    "    nlp=spacy.load(\"en_core_web_md\")\n",
    "    doc=nlp(text_without_stopwords)\n",
    "    \n",
    "    updated_words=[lemmatizer.lemmatize(word.text,pos=\"v\") if word.pos_==\"VERB\" else word.text for word in doc]\n",
    "    \n",
    "    #Returning the preprocessed text\n",
    "    return \" \".join(updated_words)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b76c3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I was amazed looking at his phone have to say iam impressed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7779d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazed look phone say iam impress\n"
     ]
    }
   ],
   "source": [
    "Testing the model\n",
    "print(preprocessing(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a8d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
